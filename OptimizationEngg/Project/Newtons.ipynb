{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "from sympy import *\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEWTON\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Line search Algorithm\n",
    "\n",
    "def linesearchUpdate(xk, deriv1_xk, Q):\n",
    "    \"\"\"\n",
    "        xk:        Current value \n",
    "        deriv1_xk: First order derivative of function f(xk)\n",
    "        Q :        Positive semidefinite matrix (when the variables/constraints are converted into the standard 2nd order form)\n",
    "        \n",
    "    \"\"\"\n",
    "    pk = -1 * deriv1_xk\n",
    "    alpha = np.dot(-gradient_k,pk) / np.dot(np.dot(np.transpose(pk), Q), pk)\n",
    "    print (alpha)\n",
    "    xk1 = xk - alpha*pk\n",
    "    return xk1\n",
    "    \n",
    "def newtonsUpdate(xk, deriv1, H):\n",
    "    \"\"\"\n",
    "        xk:        Current value \n",
    "        deriv1 : 1st order derivative\n",
    "        H      : Hessian matrix (2nd order derivative)\n",
    "        \n",
    "        pk (Search direction) = - inv(H).deriv1_xk \n",
    "    \"\"\"\n",
    "    pk = np.dot(np.linalg.inv(H),  deriv1)\n",
    "    xk1 = xk - pk\n",
    "    return xk1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*x1\n",
      "2*x2\n",
      "2*x3\n",
      "\n",
      "[2.00000000000000 2.00000000000000 2.00000000000000]\n",
      "2.00000000000000\n",
      "[5.00000000000000 5.00000000000000 5.00000000000000]\n",
      "\n",
      "[10.0000000000000 10.0000000000000 10.0000000000000]\n",
      "0.400000000000000\n",
      "[5.00000000000000 5.00000000000000 5.00000000000000]\n"
     ]
    }
   ],
   "source": [
    "x1 = Symbol('x1')\n",
    "x2 = Symbol('x2')\n",
    "x3 = Symbol('x3')\n",
    "f = pow(x1,2) + pow(x2,2) + pow(x3,2)\n",
    "deriv_f_x1 = f.diff(x1)\n",
    "deriv_f_x2 = f.diff(x2)\n",
    "deriv_f_x3 = f.diff(x3)\n",
    "print (deriv_f_x1)\n",
    "print (deriv_f_x2)\n",
    "print (deriv_f_x3)\n",
    "\n",
    "# When we convert the function f into the standard 2nd order form we ge the value of Q as\n",
    "Q = np.array([[2,0,0],[0,2,0],[0,0,2]])\n",
    "xk = np.array([1,1,1], dtype=float)\n",
    "for i in range(2):\n",
    "    deriv_f_x1_s = deriv_f_x1.subs(x1,xk[0]).subs(x2,xk[1]).subs(x3, xk[2])\n",
    "    deriv_f_x2_s = deriv_f_x2.subs(x1,xk[0]).subs(x2,xk[1]).subs(x3, xk[2])\n",
    "    deriv_f_x3_s = deriv_f_x2.subs(x1,xk[0]).subs(x2,xk[1]).subs(x3, xk[2])\n",
    "#     print (deriv_f_x1_s, deriv_f_x2_s, deriv_f_x3_s)\n",
    "    \n",
    "    gradient_subs = np.array([deriv_f_x1_s, deriv_f_x2_s, deriv_f_x3_s])\n",
    "#     gradient_norm = np.linalg.norm(gradient_subs)\n",
    "    print ('')\n",
    "    print (gradient_subs)\n",
    "    xk1 = linesearchUpdate(xk=x_step, \n",
    "                                   deriv1_xk=gradient_subs, \n",
    "                                   Q=Q)\n",
    "    print(x_step_next)\n",
    "    xk = xk1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = Symbol('x1')\n",
    "x2 = Symbol('x2')\n",
    "x3 = Symbol('x3')\n",
    "f = pow(x1,2) + pow(x2,2) + pow(x3,2)\n",
    "deriv_f_x1 = f.diff(x1)\n",
    "deriv_f_x2 = f.diff(x2)\n",
    "deriv_f_x3 = f.diff(x3)\n",
    "print (deriv_f_x1)\n",
    "print (deriv_f_x2)\n",
    "print (deriv_f_x3)\n",
    "\n",
    "# When we convert the function f into the standard 2nd order form we ge the value of Q as\n",
    "Q = np.array([[2,0,0],[0,2,0],[0,0,2]])\n",
    "xk = np.array([1,1,1])\n",
    "c = np.array([0,0,0])\n",
    "for i in range(4):\n",
    "    gradient_k = np.dot(Q, xk) - c\n",
    "    print (gradient_k)\n",
    "    gradient_norm = np.linalg.norm(gradient_k)\n",
    "    print ('')\n",
    "    print (gradient_k, gradient_norm)\n",
    "    x_step_next = linesearchUpdate(xk=x_step, \n",
    "                                   deriv1_xk=gradient_k, \n",
    "                                   Q=Q)\n",
    "    print(x_step_next)\n",
    "    xk = x_step_next\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newtons Method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution d(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2*x1 2*x2 2*x3]\n",
      "####### Gradient Norm:  0.0\n",
      "[ 0.  0.  0.]\n",
      "####### Gradient Norm:  0.0\n",
      "[ 0.  0.  0.]\n",
      "####### Gradient Norm:  0.0\n",
      "[ 0.  0.  0.]\n",
      "####### Gradient Norm:  0.0\n",
      "[ 0.  0.  0.]\n",
      "####### Gradient Norm:  0.0\n",
      "[ 0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "x1 = Symbol('x1')\n",
    "x2 = Symbol('x2')\n",
    "x3 = Symbol('x3')\n",
    "f = pow(x1,2) + pow(x2,2) + pow(x3,2)\n",
    "deriv_f_x1 = f.diff(x1)\n",
    "deriv_f_x2 = f.diff(x2)\n",
    "deriv_f_x3 = f.diff(x3)\n",
    "\n",
    "f = pow(x1,2) + pow(x2,2) + pow(x3,2)\n",
    "deriv_1 = np.array([f.diff(x1), f.diff(x2), f.diff(x3)])\n",
    "deriv_2 = np.array([[deriv_1[0].diff(x1), deriv_1[0].diff(x2), deriv_1[0].diff(x3)],\n",
    "                    [deriv_1[1].diff(x1), deriv_1[1].diff(x2), deriv_1[1].diff(x3)],\n",
    "                    [deriv_1[2].diff(x1), deriv_1[2].diff(x2), deriv_1[2].diff(x3)]])\n",
    "\n",
    "print(deriv_1)\n",
    "\n",
    "\n",
    "# H = np.array([[2,0,0],[0,2,0],[0,0,2]])\n",
    "xk = np.array([0,0,0])\n",
    "\n",
    "for i in range(5):\n",
    "    gradient = np.array([eq.evalf(subs={x1:xk[0], x2:xk[1], x3:xk[2]}) for eq in deriv_1], dtype=float)\n",
    "    hessian = np.array([cell.evalf(subs={x1:xk[0], x2:xk[1], x3:xk[2]}) \n",
    "                        for arrX in deriv_2 for cell in arrX], dtype=float).reshape(len(xk), len(xk))\n",
    "    print (\"####### Gradient Norm: \", np.linalg.norm(gradient))\n",
    "    xk1 = newtonsUpdate(xk, deriv1=gradient, H=hessian)\n",
    "    xk = xk1\n",
    "    \n",
    "    print(xk1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution d(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def newtons2Val(xk, is_print):\n",
    "    gradient = np.array([eq.evalf(subs={x1:xk[0], x2:xk[1]}) for eq in deriv_1], dtype=float)\n",
    "    if is_print:\n",
    "        print(gradient)\n",
    "        print('gradient NORM: ', np.linalg.norm(gradient))\n",
    "    hessian = np.array([cell.evalf(subs={x1:xk[0], x2:xk[1]}) \n",
    "                        for arrX in deriv_2 for cell in arrX], dtype=float).reshape(len(xk), len(xk))\n",
    "\n",
    "    xk1 = newtonsUpdate(xk, deriv1=gradient, H=hessian)\n",
    "    return xk1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.18182126e-125  -2.00000000e+000]\n",
      "gradient NORM:  2.0\n",
      "[  4.72728505e-125   9.45457010e-125]\n",
      "gradient NORM:  1.0570530726e-124\n",
      "[  4.72728505e-125   9.45457010e-125]\n",
      "gradient NORM:  1.0570530726e-124\n",
      "[  4.72728505e-125   9.45457010e-125]\n",
      "gradient NORM:  1.0570530726e-124\n",
      "[  4.72728505e-125   9.45457010e-125]\n",
      "gradient NORM:  1.0570530726e-124\n"
     ]
    }
   ],
   "source": [
    "x1 = Symbol('x1')\n",
    "x2 = Symbol('x2')\n",
    "f = pow(x1,2) + 2*pow(x2,2) - 2*x1*x2 - 2*x2\n",
    "deriv_1 = np.array([f.diff(x1), f.diff(x2)])\n",
    "deriv_2 = np.array([[deriv_1[0].diff(x1),deriv_1[0].diff(x2)],\n",
    "                    [deriv_1[1].diff(x1),deriv_1[1].diff(x2)]])\n",
    "xk = np.array([0,0])\n",
    "\n",
    "for i in range(5):\n",
    "    xk = newtons2Val(xk, is_print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution d(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-400*x1*(-x1**2 + x2) + 2*x1 - 2 -200*x1**2 + 200*x2]\n",
      "[[1200*x1**2 - 400*x2 + 2 -400*x1]\n",
      " [-400*x1 200]]\n",
      "[-215.6  -88. ]\n",
      "gradient NORM:  232.867687754\n",
      "[-4.63781641 -0.12220679]\n",
      "gradient NORM:  4.63942621407\n",
      "[ 1146.45069037  -751.47563227]\n",
      "gradient NORM:  1370.78984945\n",
      "[ -4.73110379e-01  -1.98207786e-05]\n",
      "gradient NORM:  0.473110379106\n",
      "[ 22.38520499 -11.19265967]\n",
      "gradient NORM:  25.0274455967\n"
     ]
    }
   ],
   "source": [
    "x1 = Symbol('x1')\n",
    "x2 = Symbol('x2')\n",
    "f = 100*pow(x2-pow(x1,2),2) + pow(1-x1,2)\n",
    "deriv_1 = np.array([f.diff(x1), f.diff(x2)])\n",
    "deriv_2 = np.array([[deriv_1[0].diff(x1),deriv_1[0].diff(x2)],\n",
    "                    [deriv_1[1].diff(x1),deriv_1[1].diff(x2)]])\n",
    "print(deriv_1)\n",
    "print(deriv_2)\n",
    "xk = np.array([-1.2,1])\n",
    "\n",
    "for i in range(5):\n",
    "    xk = newtons2Val(xk, is_print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution d(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4*(x1 + x2**2)**3 8*x2*(x1 + x2**2)**3 + 2*x2]\n",
      "[[12*(x1 + x2**2)**2 24*x2*(x1 + x2**2)**2]\n",
      " [24*x2*(x1 + x2**2)**2 48*x2**2*(x1 + x2**2)**2 + 8*(x1 + x2**2)**3 + 2]]\n",
      "[  6.78567249 -29.28120165]\n",
      "gradient NORM:  30.0571808614\n",
      "[ 0.3465133  -0.49853495]\n",
      "gradient NORM:  0.607131423051\n",
      "[  9.78697590e-04  -1.38103693e-08]\n",
      "gradient NORM:  0.000978697589731\n",
      "[  2.23501084e-06  -6.45184384e-29]\n",
      "gradient NORM:  2.23501083512e-06\n",
      "[  5.10400096e-09  -1.87647116e-62]\n",
      "gradient NORM:  5.10400095597e-09\n"
     ]
    }
   ],
   "source": [
    "x1 = Symbol('x1')\n",
    "x2 = Symbol('x2')\n",
    "f = pow(x1+pow(x2, 2),4) + pow(x2,2)\n",
    "deriv_1 = np.array([f.diff(x1), f.diff(x2)])\n",
    "deriv_2 = np.array([[deriv_1[0].diff(x1),deriv_1[0].diff(x2)],\n",
    "                    [deriv_1[1].diff(x1),deriv_1[1].diff(x2)]])\n",
    "print(deriv_1)\n",
    "print(deriv_2)\n",
    "xk = np.array([2,-2])\n",
    "\n",
    "for i in range(25):\n",
    "    if (i+1)%5 == 0:\n",
    "        xk = newtons2Val(xk, is_print=True)\n",
    "    else:\n",
    "        xk = newtons2Val(xk, is_print=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution d(5) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2*x1 - 2 4*x2*(x2**2 + 0.75) + 2*x2 - 2]\n",
      "[[2 0]\n",
      " [0 12*x2**2 + 5.0]]\n",
      "[  2. -44.]\n",
      "gradient NORM:  44.0454310911\n",
      "[  4.72728505e-125  -1.42524097e+001]\n",
      "gradient NORM:  14.2524097073\n",
      "[  4.72728505e-125  -5.03595579e+000]\n",
      "gradient NORM:  5.035955789\n",
      "[  4.72728505e-125  -1.38897465e+000]\n",
      "gradient NORM:  1.38897464944\n",
      "[  4.72728505e-125   1.81756576e-001]\n",
      "gradient NORM:  0.181756576395\n"
     ]
    }
   ],
   "source": [
    "c = 1\n",
    "x1 = Symbol('x1')\n",
    "x2 = Symbol('x2')\n",
    "f = pow(x1-1, 2) + pow(x2-1, 2) + c*pow((pow(x1,0) + pow(x2,2) - 0.25), 2)\n",
    "deriv_1 = np.array([f.diff(x1), f.diff(x2)])\n",
    "deriv_2 = np.array([[deriv_1[0].diff(x1),deriv_1[0].diff(x2)],\n",
    "                    [deriv_1[1].diff(x1),deriv_1[1].diff(x2)]])\n",
    "print(deriv_1)\n",
    "print(deriv_2)\n",
    "xk = np.array([2,-2])\n",
    "\n",
    "for i in range(5):\n",
    "#     if (i+1)%5 == 0:\n",
    "    xk = newtons2Val(xk, is_print=True)\n",
    "#     else:\n",
    "#         xk = newtons2Val(xk, is_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2*x1 - 2 40*x2*(x2**2 + 0.75) + 2*x2 - 2]\n",
      "[[2 0]\n",
      " [0 120*x2**2 + 32.0]]\n",
      "[  4.72728505e-125  -1.81199080e+000]\n",
      "gradient NORM:  1.81199080103\n",
      "[  4.72728505e-125  -8.04495554e-017]\n",
      "gradient NORM:  8.0449555424e-17\n",
      "[  4.72728505e-125  -8.04495554e-017]\n",
      "gradient NORM:  8.0449555424e-17\n",
      "[  4.72728505e-125  -8.04495554e-017]\n",
      "gradient NORM:  8.0449555424e-17\n"
     ]
    }
   ],
   "source": [
    "c = 10\n",
    "x1 = Symbol('x1')\n",
    "x2 = Symbol('x2')\n",
    "f = pow(x1-1, 2) + pow(x2-1, 2) + c*pow((pow(x1,0) + pow(x2,2) - 0.25), 2)\n",
    "deriv_1 = np.array([f.diff(x1), f.diff(x2)])\n",
    "deriv_2 = np.array([[deriv_1[0].diff(x1),deriv_1[0].diff(x2)],\n",
    "                    [deriv_1[1].diff(x1),deriv_1[1].diff(x2)]])\n",
    "print(deriv_1)\n",
    "print(deriv_2)\n",
    "xk = np.array([2,-2])\n",
    "\n",
    "for i in range(20):\n",
    "    if (i+1)%5 == 0:\n",
    "        xk = newtons2Val(xk, is_print=True)\n",
    "    else:\n",
    "        xk = newtons2Val(xk, is_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2*x1 - 2 400*x2*(x2**2 + 0.75) + 2*x2 - 2]\n",
      "[[2 0]\n",
      " [0 1200*x2**2 + 302.0]]\n",
      "[  4.72728505e-125  -1.94004158e+001]\n",
      "gradient NORM:  19.4004158389\n",
      "[  4.72728505e-125   9.37571443e-018]\n",
      "gradient NORM:  9.37571443109e-18\n",
      "[  4.72728505e-125   9.37571443e-018]\n",
      "gradient NORM:  9.37571443109e-18\n",
      "[  4.72728505e-125   9.37571443e-018]\n",
      "gradient NORM:  9.37571443109e-18\n"
     ]
    }
   ],
   "source": [
    "c = 100\n",
    "x1 = Symbol('x1')\n",
    "x2 = Symbol('x2')\n",
    "f = pow(x1-1, 2) + pow(x2-1, 2) + c*pow((pow(x1,0) + pow(x2,2) - 0.25), 2)\n",
    "deriv_1 = np.array([f.diff(x1), f.diff(x2)])\n",
    "deriv_2 = np.array([[deriv_1[0].diff(x1),deriv_1[0].diff(x2)],\n",
    "                    [deriv_1[1].diff(x1),deriv_1[1].diff(x2)]])\n",
    "print(deriv_1)\n",
    "print(deriv_2)\n",
    "xk = np.array([2,-2])\n",
    "\n",
    "for i in range(20):\n",
    "    if (i+1)%5 == 0:\n",
    "        xk = newtons2Val(xk, is_print=True)\n",
    "    else:\n",
    "        xk = newtons2Val(xk, is_print=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BFGS UPDATE\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BFGSUpdate(xk, Bk, deriv1_xk, Q):\n",
    "    \"\"\"\n",
    "        xk:        Current value \n",
    "        Bk:        Approximated 2nd order matrix\n",
    "        deriv1_xk: First order derivative of function f(xk)\n",
    "        Q :        Q formed when we convert the function in standard form\n",
    "                   Also equivallent to Hessian matrix, Computation is needed only once\n",
    "                   No update is required\n",
    "        \n",
    "        pk (Search direction) = - inv(Bk).deriv1_xk \n",
    "    \"\"\"\n",
    "    pk = -1 * np.dot(np.linalg.inv(Bk),deriv1_xk)\n",
    "    alpha = np.dot(np.transpose(pk), deriv1_xk) / np.dot(np.dot(np.transpose(pk), Q), pk)\n",
    "    xk1 = xk - alpha*pk\n",
    "    return xk1\n",
    "\n",
    "def updateBk(step, deriv_1, xk, xk1, gradient_xk, Bk):\n",
    "    \"\"\"\n",
    "        step:             Step Num, int\n",
    "        deriv_1           1st order derivative of the input function \n",
    "        xk:               previous solution\n",
    "        xk1:              New Solution\n",
    "        gradient_xk:      deriv_1 evaluated at xk1\n",
    "        Bk:               Approximated 2nd order matrix\n",
    "    \"\"\"\n",
    "    gradient_xk1 =  np.array([eq.evalf(subs={x1:xk1[0], x2:xk1[1], x3:xk1[2]}) \n",
    "                              for eq in deriv_1], dtype=float)\n",
    "    print ('Gradient at xk%s: '%str(step), gradient_xk1)\n",
    "    Sk = xk1 - xk\n",
    "    Yk = gradient_xk1 - gradient_xk\n",
    "    numerator = np.dot(np.dot(Bk,Sk),np.transpose(np.dot(Bk,Sk)))\n",
    "    denominator = np.dot(np.transpose(Sk),np.dot(Bk,Sk))\n",
    "    Bk1 = Bk - (numerator/denominator) + (np.dot(Yk, np.transpose(Yk))/np.dot(np.transpose(Yk), Yk))\n",
    "    \n",
    "    return Bk1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution d(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First order Derivative:  [2*x1 2*x2 2*x3]\n",
      "Gradient at xk0 is:  [ 0.  0.  0.]\n",
      "####### Gradient Norm:  0.0\n"
     ]
    }
   ],
   "source": [
    "f = pow(x1,2) + pow(x2,2) + pow(x3,2)\n",
    "deriv_f_x1 = f.diff(x1)\n",
    "deriv_f_x2 = f.diff(x2)\n",
    "deriv_f_x3 = f.diff(x3)\n",
    "\n",
    "f = pow(x1,2) + pow(x2,2) + pow(x3,2)\n",
    "deriv_1 = np.array([f.diff(x1), f.diff(x2), f.diff(x3)])\n",
    "print ('First order Derivative: ', deriv_1)\n",
    "Q = np.array([[2,0,0],[0,2,0],[0,0,2]])  # Q is obtained by converting the funciton into quadratic form, which is equivallent to 2nd order derivative in all our case\n",
    "\n",
    "# Initialize BK\n",
    "Bk = np.eye(3)\n",
    "\n",
    "# Initialize Xk\n",
    "xk = np.array([0,0,0])\n",
    "\n",
    "for step in range(5):\n",
    "    gradient = np.array([eq.evalf(subs={x1:xk[0], x2:xk[1], x3:xk[2]}) for eq in deriv_1], dtype=float)\n",
    "    print ('Gradient at xk%s is: '%str(step), gradient)\n",
    "    gradientNorm = np.linalg.norm(gradient)\n",
    "    print (\"####### Gradient Norm: \", gradientNorm)\n",
    "    if gradientNorm == 0:\n",
    "        break\n",
    "        \n",
    "    xk1 = BFGSUpdate(xk=xk, Bk=Bk, deriv1_xk=gradient, Q=Q)\n",
    "    Bk1 = updateBk(step, deriv_1, xk, xk1, gradient_xk, Bk)\n",
    "    \n",
    "    # Parameter UPdate\n",
    "    xk = xk1\n",
    "    Bk = Bk1\n",
    "    \n",
    "    print(xk1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Solution d(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = pow(x1,2) + pow(x2,2) + pow(x3,2)\n",
    "deriv_f_x1 = f.diff(x1)\n",
    "deriv_f_x2 = f.diff(x2)\n",
    "deriv_f_x3 = f.diff(x3)\n",
    "\n",
    "f = pow(x1,2) + pow(x2,2) + pow(x3,2)\n",
    "deriv_1 = np.array([f.diff(x1), f.diff(x2), f.diff(x3)])\n",
    "print ('First order Derivative: ', deriv_1)\n",
    "Q = np.array([[2,0,0],[0,2,0],[0,0,2]])  # Q is obtained by converting the funciton into quadratic form, which is equivallent to 2nd order derivative in all our case\n",
    "\n",
    "# Initialize BK\n",
    "Bk = np.eye(3)\n",
    "\n",
    "# Initialize Xk\n",
    "xk = np.array([0,0,0])\n",
    "\n",
    "for step in range(5):\n",
    "    gradient = np.array([eq.evalf(subs={x1:xk[0], x2:xk[1], x3:xk[2]}) for eq in deriv_1], dtype=float)\n",
    "    print ('Gradient at xk%s is: '%str(step), gradient)\n",
    "    gradientNorm = np.linalg.norm(gradient)\n",
    "    print (\"####### Gradient Norm: \", gradientNorm)\n",
    "    if gradientNorm == 0:\n",
    "        break\n",
    "        \n",
    "    xk1 = BFGSUpdate(xk=xk, Bk=Bk, deriv1_xk=gradient, Q=Q)\n",
    "    Bk1 = updateBk(step, deriv_1, xk, xk1, gradient_xk, Bk)\n",
    "    \n",
    "    # Parameter UPdate\n",
    "    xk = xk1\n",
    "    Bk = Bk1\n",
    "    \n",
    "    print(xk1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
