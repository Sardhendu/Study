{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "from sympy.solvers import solve\n",
    "from sympy import Symbol\n",
    "import numpy as np\n",
    "import cmath\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epsilon = 10e-5\n",
    "\n",
    "def CGUpdate(xk, Bk, deriv1_xk, Q):\n",
    "    \"\"\"\n",
    "        xk:        Current value \n",
    "        Bk:        Approximated 2nd order matrix\n",
    "        deriv1_xk: First order derivative of function f(xk)\n",
    "        Q :        Q formed when we convert the function in standard form\n",
    "                   Also equivallent to Hessian matrix, Computation is needed only once\n",
    "                   No update is required\n",
    "        \n",
    "        pk (Search direction) = - inv(Bk).deriv1_xk \n",
    "    \"\"\"\n",
    "#     print('')\n",
    "#     print('')\n",
    "#     print(Bk)\n",
    "#     print('')\n",
    "#     print(deriv1_xk)\n",
    "#     print('')\n",
    "#     print('')\n",
    "    pk = -1 * np.dot(np.linalg.inv(Bk),deriv1_xk)\n",
    "    alpha = np.dot(np.transpose(pk), deriv1_xk) / np.dot(np.dot(np.transpose(pk), Q), pk)\n",
    "    xk1 = xk - alpha*pk\n",
    "    return xk1\n",
    "\n",
    "def updateBk(step, deriv_1, xk, xk1, gradient_xk, Bk, numVariables):\n",
    "    \"\"\"\n",
    "        step:             Step Num, int\n",
    "        deriv_1           1st order derivative of the input function \n",
    "        xk:               previous solution\n",
    "        xk1:              New Solution\n",
    "        gradient_xk:      deriv_1 evaluated at xk1\n",
    "        Bk:               Approximated 2nd order matrix\n",
    "    \"\"\"\n",
    "    if numVariables == 3:\n",
    "        gradient_xk1 =  np.array([eq.evalf(subs={x1:xk1[0], x2:xk1[1], x3:xk1[2]}) \n",
    "                                  for eq in deriv_1], dtype='float32')\n",
    "    elif numVariables == 2:\n",
    "        gradient_xk1 =  np.array([eq.evalf(subs={x1:xk1[0], x2:xk1[1]}) \n",
    "                                  for eq in deriv_1], dtype='float32')\n",
    "    else:\n",
    "        raise ValueError('Num Features doesnt match the hadled condition')\n",
    "        \n",
    "#     print ('Gradient at xk%s: '%str(step), gradient_xk1)\n",
    "    Sk = xk1 - xk\n",
    "    Sk = np.array(Sk).reshape(len(Sk), 1)\n",
    "#     print ('Sk at xk%s: %s \\n'%(str(step), str(Sk.shape)), Sk)\n",
    "    Yk = gradient_xk1 - gradient_xk\n",
    "    Yk = np.array(Yk).reshape(len(Yk), 1)\n",
    "#     print ('Yk at xk%s: %s \\n'%(str(step), str(Yk.shape)), Yk)\n",
    "    numerator = np.dot(np.dot(Bk,Sk),np.transpose(np.dot(Bk,Sk)))\n",
    "#     print ('numerator at xk%s: \\n'%str(step), numerator)\n",
    "    denominator = np.dot(np.transpose(Sk),np.dot(Bk,Sk))\n",
    "#     print ('denominator at xk%s: \\n'%str(step), denominator)\n",
    "    RHS = np.dot(Yk, np.transpose(Yk))/np.dot(np.transpose(Yk), Yk)\n",
    "#     print ('RHS at xk%s: \\n'%str(step), RHS)\n",
    "    Bk1 = Bk - (numerator/denominator) + RHS\n",
    "#     print ('BkBkBkBkBkBkBkBkBkBkBkBkBk\\n', Bk1)\n",
    "    return Bk1\n",
    "\n",
    "def iterate(f, xk, deriv_1, Q, Bk, numFeatures, numSteps, should_print):\n",
    "    fx_arr = []\n",
    "    gradientNorm_arr = []\n",
    "    for step in range(numSteps):\n",
    "        if numFeatures == 3:\n",
    "            fx = f.evalf(subs={x1:xk[0], x2:xk[1], x3:xk[2]})\n",
    "            gradient_xk = np.array([eq.evalf(subs={x1:xk[0], x2:xk[1], x3:xk[2]}) for eq in deriv_1], \n",
    "                                   dtype='float32')\n",
    "        elif numFeatures == 2:\n",
    "            fx = f.evalf(subs={x1:xk[0], x2:xk[1]})\n",
    "            gradient_xk = np.array([eq.evalf(subs={x1:xk[0], x2:xk[1]}) for eq in deriv_1], \n",
    "                                   dtype='float32')\n",
    "        else:\n",
    "            raise ValueError('Num Features doesnt match the hadled condition')\n",
    "        \n",
    "        fx_arr.append(fx)\n",
    "        gradientNorm = np.linalg.norm(gradient_xk)\n",
    "        gradientNorm_arr.append(gradientNorm)\n",
    "        \n",
    "        if should_print:\n",
    "            if (step+1)%should_print == 0:\n",
    "                print('')\n",
    "                print ('##########################################################')\n",
    "                print ('Function F at x: f(x) ', fx)\n",
    "                print ('Gradient at xk%s is: '%str(step), gradient_xk)\n",
    "                print (\"####### Gradient Norm: \", gradientNorm)\n",
    "                print('The updated Value Bk%s is \\n'%(step+1), Bk)\n",
    "                print('The updated Value xk%s is \\n'%(step+1), xk)\n",
    "                \n",
    "                \n",
    "                \n",
    "#         print ('Gradient at xk%s is: '%str(step), gradient_xk)\n",
    "#         gradientNorm = np.linalg.norm(gradient_xk)\n",
    "#         print (\"####### Gradient Norm: \", gradientNorm)\n",
    "#         if gradientNorm == 0:\n",
    "#             break\n",
    "        if np.sum((gradientNorm/(1+np.abs(gradient_xk))) <= epsilon) == len(gradient_xk) or (step == 1000):\n",
    "            break\n",
    "            \n",
    "#         print ('xk at step %s: \\n'%str(step), xk)\n",
    "        xk1 = BFGSUpdate(xk=xk, Bk=Bk, deriv1_xk=gradient_xk, Q=Q)\n",
    "#         print ('xk1 at step %s: \\n'%str(step), xk1)\n",
    "        \n",
    "        Bk1 = updateBk(step+1, deriv_1, xk, xk1, gradient_xk, Bk, numVariables=numFeatures)\n",
    "\n",
    "        # Parameter UPdate\n",
    "        xk = xk1\n",
    "        Bk = Bk1\n",
    "\n",
    "    return fx_arr, gradientNorm_arr\n",
    "\n",
    "\n",
    "def plot(x_arr, rows=1, columns=2, figsize=(12, 6)):\n",
    "    fig1, axs = plt.subplots(rows,columns, figsize=figsize, facecolor='w', edgecolor='k')\n",
    "    if columns>1:\n",
    "        axs = axs.ravel()\n",
    "    for no, arrVal in enumerate(x_arr):\n",
    "        axs[no].plot(np.arange(len(arrVal)), arrVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import linesearch\n",
    "import scipy as sp\n",
    "import scipy.optimize\n",
    "epsilon = 10e-5\n",
    "\n",
    "# class SetFunction()\n",
    "#     def __init__(self):\n",
    "#         self.fnc = \n",
    "def function3(x):\n",
    "#     print(x)\n",
    "    return 100*pow(x[1]-pow(x[0],2),2) + pow(1-x[1],2)\n",
    "\n",
    "def objective3(x):\n",
    "#     print(x)\n",
    "    a = -400*x[0]*(-x[0]**2 + x[1]) + 2*x[1] - 2\n",
    "    b = -200*x[0]**2 + 200*x[1]\n",
    "    return [a,b]\n",
    "\n",
    "\n",
    "def function4(x):\n",
    "#     print(x)\n",
    "    return 100*pow(x[1]-pow(x[0],2),2) + pow(1-x[1],2)\n",
    "\n",
    "def objective4(x):\n",
    "#     print(x)\n",
    "    a = -400*x[0]*(-x[0]**2 + x[1]) + 2*x[1] - 2\n",
    "    b = -200*x[0]**2 + 200*x[1]\n",
    "    return [a,b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def iterateNonQuadratic(f, xk, deriv_1, funciton, objective, numFeature, numSteps, should_print):\n",
    "    fx_arr = []\n",
    "    gradientNorm_arr = []\n",
    "    alpha_arr = []\n",
    "    for step in range(numSteps):\n",
    "        print('stepstepstep ', step)\n",
    "        # Solve for gradient\n",
    "        fx = f.evalf(subs={x1:xk[0], x2:xk[1]})\n",
    "        fx_arr.append(fx)\n",
    "        gradient_xk = np.array([eq.evalf(subs={x1:xk[0], x2:xk[1]}) for eq in deriv_1], dtype='float32')\n",
    "        gradientNorm = np.linalg.norm(gradient_xk)\n",
    "        gradientNorm_arr.append(np.linalg.norm(gradientNorm))\n",
    "        if np.sum((gradientNorm/(1+np.abs(gradient_xk))) <= epsilon) == len(gradient_xk) or (step == 1000):\n",
    "            print('The check (gradient norm equation reach a val < epsilon, HENCE BREAKING OUT OF LOOP)')\n",
    "            break\n",
    "#         print()\n",
    "\n",
    "        pk = -1 * gradient_xk\n",
    "        a = linesearch.line_search_wolfe2(function,objective,xk,pk)\n",
    "        print(a)\n",
    "        if not a[0]:\n",
    "            alpha = float(alpha_arr[len(alpha_arr)-1]/2)\n",
    "#             alpha = 0.01\n",
    "        else:\n",
    "            alpha_arr.append(a[0])\n",
    "            alpha = alpha_arr[len(alpha_arr)-1]\n",
    "\n",
    "        xk1 = xk - (alpha*gradient_xk)\n",
    "        print('aaaaaa ', a[0], a)\n",
    "#\n",
    "        xk = xk1\n",
    "        \n",
    "    return fx_arr, gradientNorm_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-400*x1*(-x1**2 + x2) + 2*x1 - 2\n",
      "-200*x1**2 + 200*x2\n",
      "stepstepstep  0\n",
      "(0.00091722178048143769, 11, 1, 0.58741103959519003, 19.360010070802293, [30.716548311490072, 15.243307274610629])\n",
      "aaaaaa  0.000917221780481 (0.00091722178048143769, 11, 1, 0.58741103959519003, 19.360010070802293, [30.716548311490072, 15.243307274610629])\n",
      "stepstepstep  1\n",
      "(0.00096827509435541497, 9, 1, 0.01293196113899988, 0.58741103959519003, [3.9410171798350788, 1.8527583099853473])\n",
      "aaaaaa  0.000968275094355 (0.00096827509435541497, 9, 1, 0.01293196113899988, 0.58741103959519003, [3.9410171798350788, 1.8527583099853473])\n",
      "stepstepstep  2\n",
      "(0.0067990707499102788, 7, 1, 0.0028484533409359283, 0.01293196113899988, [0.15338823565591886, 0.022737835558928055])\n",
      "aaaaaa  0.00679907074991 (0.0067990707499102788, 7, 1, 0.0028484533409359283, 0.01293196113899988, [0.15338823565591886, 0.022737835558928055])\n",
      "stepstepstep  3\n",
      "(None, 13, 0, None, 0.0028484533409359283, None)\n",
      "aaaaaa  None (None, 13, 0, None, 0.0028484533409359283, None)\n",
      "stepstepstep  4\n",
      "(None, 13, 0, None, 0.0028509637691843119, None)\n",
      "aaaaaa  None (None, 13, 0, None, 0.0028509637691843119, None)\n",
      "stepstepstep  5\n",
      "(None, 13, 0, None, 0.0028547579312173908, None)\n",
      "aaaaaa  None (None, 13, 0, None, 0.0028547579312173908, None)\n",
      "stepstepstep  6\n",
      "(None, 13, 0, None, 0.0028597729189677457, None)\n",
      "aaaaaa  None (None, 13, 0, None, 0.0028597729189677457, None)\n",
      "stepstepstep  7\n",
      "(None, 13, 0, None, 0.0028660063010680211, None)\n",
      "aaaaaa  None (None, 13, 0, None, 0.0028660063010680211, None)\n",
      "stepstepstep  8\n",
      "(None, 13, 0, None, 0.0028734036898980953, None)\n",
      "aaaaaa  None (None, 13, 0, None, 0.0028734036898980953, None)\n",
      "stepstepstep  9\n",
      "(None, 13, 0, None, 0.0028818978243443818, None)\n",
      "aaaaaa  None (None, 13, 0, None, 0.0028818978243443818, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sam/App-Setup/anaconda/lib/python3.6/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-3f0051e5aece>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mfx_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradientNorm_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterateNonQuadratic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderiv_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumFeature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumSteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_print\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfx_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradientNorm_arr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot' is not defined"
     ]
    }
   ],
   "source": [
    "x1 = Symbol('x1')\n",
    "x2 = Symbol('x2')\n",
    "f = 100*pow(x2-pow(x1,2),2) + pow(1-x1,2)\n",
    "deriv_1 = np.array([f.diff(x1), f.diff(x2)])\n",
    "print(deriv_1[0])\n",
    "print(deriv_1[1])\n",
    "\n",
    "# Initialize Xk\n",
    "xk = np.array([-1.2,1], dtype='float32')\n",
    "\n",
    "fx_array, gradientNorm_arr = iterateNonQuadratic(f, xk, deriv_1, numFeature=2, numSteps=10, should_print=1)  \n",
    "plot([fx_array, gradientNorm_arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
