{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ssteepest descent for a funtion\n",
    "\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "from sympy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4*x1**2 + 4*x1*x2 - 3*x1 + 2*x2**2\n",
      "8*x1 + 4*x2 - 3\n",
      "4*x1 + 4*x2\n"
     ]
    }
   ],
   "source": [
    "x1 = Symbol('x1')\n",
    "x2 = Symbol('x2')\n",
    "f = 4*pow(x1,2) + 2*pow(x2,2) + 4*x1*x2 - 3*x1\n",
    "\n",
    "deriv_f_x1 = f.diff(x1)\n",
    "deriv_f_x2 = f.diff(x2)\n",
    "print (f)\n",
    "print (deriv_f_x1)\n",
    "print (deriv_f_x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of function at xstep at iteration 0 is:  [21.0000000000000 16.0000000000000]\n",
      "f_x_stepNext at current state is:  [-21.0*alpha + 2 -16.0*alpha + 2]\n",
      "f_x_stepNext_subs for current state is :  [-232.0*alpha + 21 -148.0*alpha + 16]\n",
      "The new alpha at Iteration 0 is:  [0.0962707182320442]\n",
      "The next step at Iteration 0 is:  [-0.0216850828729283 0.459668508287293]\n",
      "\n",
      "Gradient of function at xstep at iteration 1 is:  [-1.33480662983425 1.75193370165746]\n",
      "f_x_stepNext at current state is:  [1.33480662983425*alpha - 0.0216850828729283\n",
      " -1.75193370165746*alpha + 0.459668508287293]\n",
      "f_x_stepNext_subs for current state is :  [3.6707182320442*alpha - 1.33480662983425\n",
      " -1.66850828729282*alpha + 1.75193370165746]\n",
      "The new alpha at Iteration 1 is:  [0.620106761565837]\n",
      "The next step at Iteration 1 is:  [0.806037533670200 -0.626717425925563]\n",
      "\n",
      "Gradient of function at xstep at iteration 2 is:  [0.941430565659350 0.717280430978549]\n",
      "f_x_stepNext at current state is:  [-0.94143056565935*alpha + 0.8060375336702\n",
      " -0.717280430978549*alpha - 0.626717425925563]\n",
      "f_x_stepNext_subs for current state is :  [-10.400566249189*alpha + 0.94143056565935\n",
      " -6.63484398655159*alpha + 0.717280430978549]\n",
      "The new alpha at Iteration 2 is:  [0.0962707182320444]\n",
      "The next step at Iteration 2 is:  [0.715405336948575 -0.695770528189658]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_step = np.array([2,2])\n",
    "# print (deriv_f_x1)\n",
    "# print (deriv_f_x2)\n",
    "iteration = 0\n",
    "numSteps = 3\n",
    "while (iteration<numSteps):\n",
    "    # Solve for gradient\n",
    "    deriv_f_x1_s = deriv_f_x1.subs(x1,x_step[0]).subs(x2,x_step[1])\n",
    "    deriv_f_x2_s = deriv_f_x2.subs(x1,x_step[0]).subs(x2,x_step[1])\n",
    "\n",
    "    gradient_subs = np.array([deriv_f_x1_s, deriv_f_x2_s])\n",
    "    print ('Gradient of function at xstep at iteration %s is: '%(iteration), gradient_subs)\n",
    "\n",
    "    f_x_stepNext = x_step - np.array([Symbol('alpha')*deriv_f_x1_s, Symbol('alpha')*deriv_f_x2_s])\n",
    "    print (\"f_x_stepNext at current state is: \",  f_x_stepNext)\n",
    "    f_x_stepNext_subs = np.array([deriv_f_x1.subs(x1, f_x_stepNext[0]).subs(x2, f_x_stepNext[1]), \n",
    "                      deriv_f_x2.subs(x1, f_x_stepNext[0]).subs(x2, f_x_stepNext[1])])\n",
    "    print (\"f_x_stepNext_subs for current state is : \", f_x_stepNext_subs)\n",
    "    f_x_stepNext_subs = np.dot(f_x_stepNext_subs, gradient_subs)\n",
    "\n",
    "    alpha = solve(str(f_x_stepNext_subs))\n",
    "    print ('The new alpha at Iteration %s is: '%(iteration), alpha)   \n",
    "\n",
    "    x_stepNext = x_step - (alpha*gradient_subs)\n",
    "    print ('The next step at Iteration %s is: '%(iteration), x_stepNext)\n",
    "    \n",
    "    x_step = x_stepNext\n",
    "    \n",
    "    iteration += 1\n",
    "    \n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Steepest descent for Quadratic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient direction :  [1 1 1] (3,)\n",
      "Gradient :  [-1 -1 -1] (3,)\n",
      "Gradient Norm :  1.73205080757\n",
      "Numerator :  3\n",
      "Denominator :  1001001\n",
      "The value of aplha :  2.997000003e-06\n",
      "The new x a step towards minimum is :  [  2.99700000e-06   2.99700000e-06   2.99700000e-06]\n",
      "\n",
      "Gradient direction :  [ 0.999997  0.997003 -1.997   ] (3,)\n",
      "Gradient :  [-0.999997 -0.997003  1.997   ] (3,)\n",
      "Gradient Norm :  2.4458164281\n",
      "Numerator :  5.98201799998\n",
      "Denominator :  3989004.02695\n",
      "The value of aplha :  1.49962696442e-06\n",
      "The new x a step towards minimum is :  [  4.49662247e-06   4.49213259e-06   2.24495056e-09]\n",
      "\n",
      "Gradient direction :  [ 0.9999955   0.99550787  0.99775505] (3,)\n",
      "Gradient :  [-0.9999955  -0.99550787 -0.99775505] (3,)\n",
      "Gradient Norm :  1.72816146802\n",
      "Numerator :  2.98654205954\n",
      "Denominator :  996507.17459\n",
      "The value of aplha :  2.99701009255e-06\n",
      "The new x a step towards minimum is :  [  7.49361909e-06   7.47567971e-06   2.99252690e-06]\n",
      "\n",
      "Gradient direction :  [ 0.99999251  0.99252432 -1.9925269 ] (3,)\n",
      "Gradient :  [-0.99999251 -0.99252432  1.9925269 ] (3,)\n",
      "Gradient Norm :  2.44033870618\n",
      "Numerator :  5.95525300086\n",
      "Denominator :  3971149.56618\n",
      "The value of aplha :  1.49962949056e-06\n",
      "The new x a step towards minimum is :  [  8.99323734e-06   8.96409845e-06   4.47479822e-09]\n",
      "\n",
      "Gradient direction :  [ 0.99999101  0.9910359   0.9955252 ] (3,)\n",
      "Gradient :  [-0.99999101 -0.9910359  -0.9955252 ] (3,)\n",
      "Gradient Norm :  1.72429829181\n",
      "Numerator :  2.97320459913\n",
      "Denominator :  992053.579512\n",
      "The value of aplha :  2.99702018171e-06\n",
      "The new x a step towards minimum is :  [  1.19902306e-05   1.19342530e-05   2.98808392e-06]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "Q1 = np.array([[1,0,0],[0,1,0],[0,0,1]])\n",
    "Q2 = np.array([[1,0,0],[0,10,0],[0,0,100]])\n",
    "Q3 = np.array([[1,0,0],[0,100,0],[0,0,10000]])\n",
    "Q4 = np.array([[1,0,0],[0,1000,0],[0,0,1000000]])\n",
    "\n",
    "Q5 = np.array([[1,0,0],[0,5,0],[0,0,25]])\n",
    "\n",
    "Q = Q4\n",
    "c = np.array([1,1,1])\n",
    "xk = np.array([0,0,0])\n",
    "\n",
    "iteration = 0\n",
    "num_steps = 4\n",
    "while iteration<=num_steps:\n",
    "    pk = -1 * (np.dot(Q, xk) - c)\n",
    "    gradient_k = np.dot(Q, xk) - c\n",
    "    gradient_norm = np.linalg.norm(gradient_k)\n",
    "    numerator = np.dot(-gradient_k,pk)\n",
    "    denominator = np.dot(np.dot(np.transpose(pk),Q), pk)\n",
    "    alpha = numerator/denominator\n",
    "    x_new = xk - alpha*gradient_k\n",
    "    xk  = x_new\n",
    "    print ('Gradient direction : ', pk, pk.shape)\n",
    "    print ('Gradient : ', gradient_k, gradient_k.shape)\n",
    "    print ('Gradient Norm : ',gradient_norm)\n",
    "    print ('Numerator : ', numerator)\n",
    "    print ('Denominator : ', denominator)\n",
    "    print ('The value of aplha : ', alpha)\n",
    "    print ('The new x a step towards minimum is : ', x_new)\n",
    "    iteration += 1\n",
    "    print ('')\n",
    "# alpha_k = np.dot(-gradient_k,pk)/np.dot(np.dot(np.transpose(pk),Q), pk)\n",
    "# print (pk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Assignment 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20*x1**3 - 12*x1 + 2*x2 + 15\n",
      "2*x1 + 24*x2**3 + 10*x2 - 7\n",
      "60*x1**2 - 12\n",
      "72*x2**2 + 10\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Question 3.3:\n",
    "\n",
    "x1 = Symbol('x1')\n",
    "x2 = Symbol('x2')\n",
    "\n",
    "f = 5*pow(x1,4) + 6*pow(x2,4) - 6*pow(x1,2) + 2*x1*x2 + 5*pow(x2,2) + 15*x1 - 7*x2 + 13\n",
    "\n",
    "deriv_f_x1 = f.diff(x1)\n",
    "deriv_f_x2 = f.diff(x2)\n",
    "deriv_f_x1x1 = deriv_f_x1.diff(x1)\n",
    "deriv_f_x2x2 = deriv_f_x2.diff(x2)\n",
    "deriv_f_x1x2 = deriv_f_x1.diff(x2)\n",
    "deriv_f_x2x1 = deriv_f_x2.diff(x1)\n",
    "\n",
    "print (deriv_f_x1)\n",
    "print (deriv_f_x2)\n",
    "print (deriv_f_x1x1)\n",
    "print (deriv_f_x2x2)\n",
    "print (deriv_f_x1x2)\n",
    "print (deriv_f_x2x1)\n",
    "\n",
    "valx1 = 1\n",
    "valx2 = 1\n",
    "i = 1\n",
    "while (i==5):\n",
    "    order1 = np.array([deriv_f_x1.subs(x1,valx1).subs(x2,valx2),deriv_f_x2.subs(x1,valx1).subs(x2,valx2)])\n",
    "    order2 =  np.array([[deriv_f_x1x1.subs(x1,valx1).subs(x2,valx2), deriv_f_x1x2],\n",
    "                        [deriv_f_x2x1, deriv_f_x2x2.subs(x1,valx1).subs(x2,valx2)] ])\n",
    "    print(order1)\n",
    "    print (order2)\n",
    "    order2_inv = np.linalg.inv(np.array(order2, dtype=float))\n",
    "    alpha_pk = np.dot(order2_inv,order1)\n",
    "    print (alpha_pk)\n",
    "    xk_1 = np.array([valx1,valx2], dtype=float) - alpha_pk\n",
    "    print (xk_1)\n",
    "    valx1 = xk_1[0]\n",
    "    valx2 = xk_1[1]\n",
    "    \n",
    "    i+=1\n",
    "    print ('')\n",
    "    print ('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
