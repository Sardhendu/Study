{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things to look for before marching to build Deep Networks\n",
    "--------\n",
    "\n",
    "* **Using Scope Variables**: We can create deep networks by writing individual code for each layers. In such a case if we want to go deeper say 10 layers deep, writing the same code would be redundant. Hence, we use scope to make the process more dynamic\n",
    "* **Optimization**: Gradient Descent optimizer is a good optimizer, But why not use something with momentum and adaptive learning rate. Such optimizers are shown to be more powerfull in many applications. Example: Try *RMSPROP (when doing Batch learning)* and *ADAM optimizer (for general cases)* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we create a re-usable funtion to add linear networks layers\n",
    "def linearActivation(numInputs, numOutputs):\n",
    "    with tf.VariableScope(\"linear\"):\n",
    "        w = tf.get_variable(dtype='float32',\n",
    "                           shape=[numInputs, numOutputs],\n",
    "                           initializer=tf.random_normal_initializer(mean=0.0, stddev=0.1),\n",
    "                           name='weight')\n",
    "        b = tf.get_variable(dtype='float32',\n",
    "                           shape=[numOuptuts],\n",
    "                           initializer=tf.constant_initializer(),\n",
    "                           name='bias')\n",
    "        \n",
    "        y_pred = tf.matmul(x,w) + b\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
